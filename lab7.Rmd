---
title: "lab7"
author: "Claire Madden"
date: "2/19/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
```


### Attach packages
```{r}
#General Packages for stuff
library(tidyverse)
library(janitor)
library(plotly)
library(here)
#Packages for spatial stuff & point pattern analysis
library(tmap)
library(sf)
library(spatstat)
library(maptools)
library(sp)
library(raster)
#Packages for cluster analysis:
library(NbClust)
library(cluster)
library(factoextra)
library(dendextend)
library(ggdendro)

```

### Get data

Red tree voles in Humboldt County

```{r}

voles <- read_sf(dsn = here("data", "redtreevoledata"), 
                 layer = "ds033") %>% 
  dplyr::select(COUNTY) %>% # get rid of all columns except county
  dplyr::filter(COUNTY == "HUM") %>% # select only rows with observations in humboldt county
  st_transform(crs = 4326) # change the projection to WGS84

# st_crs(voles) # use this to check to make sure that crs is set to what we want

plot(voles)

# point pattern analysis requires specified boundaries to perform analysis within so...

# read in data for Humboldt county

humboldt <- read_sf(dsn = here("data", "redtreevoledata"),
                    layer = "california_county_shape_file", crs = 4326) %>% 
  dplyr::filter(NAME == "Humboldt") %>% # get only humboldt county instead of all CA counties
  dplyr::select(NAME) # get rid of everything but name and geometry

# st_crs(humboldt) #same projection as red tree vole data 


plot(humboldt)

# get both datasets plotted in the same space using tmap
tm_shape(humboldt)+
  tm_fill()+
  tm_shape(voles)+
  tm_dots(size = 0.1)
# advantage of tmap (over ggplot) is currently only option that has interactive mode
# good place to get started with mapping in R is :: Geocomputation in R (Robin Lovelace) which is available for free online and you can download a package that allows you to work through all the examples!

# or the same deal in ggplot
ggplot()+
  geom_sf(data = humboldt)+
  geom_sf(data = voles)
```


Convert vole events and humboldt polygon to a point pattern + window: 

```{r}
# not all statistical spatial packages are equiped to work with sf objects

voles_sp <- as(voles, "Spatial")
voles_ppp <- as(voles_sp, "ppp")

# we will come back to this later 

## from key ##

humboldt_sp <- as(humboldt, "Spatial")
humboldt_win <- as(humboldt_sp, "owin")

voles_pb <- ppp(voles_ppp$x, voles_ppp$y, window = humboldt_win)


plot(voles_pb)

vole_qt <- quadrat.test(voles_pb, nx = 5, ny = 10) # nx and ny are number of columns/rows for the rectangles created 

# Returns: VoleQT
# Chi-squared test of CSR using quadrat counts

# data:  VolePPP 
# X-squared = 425.94, df = 45, p-value < 2.2e-16
# alternative hypothesis: two.sided 
# Reject the null hypothesis of spatial evenness! But we still don't know if more clustered or more uniform...

plot(voles_pb)
plot(vole_qt, add = TRUE, cex = 0.4)

```
Plot densities: 
```{r}

point_density <- density(voles_pb, sigma = 0.02)
plot(point_density)

# Can you start viewing this in tmap? Yes, rasterize it: 
wgs84 = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
vole_raster <- raster(point_density, crs = wgs84)

# Then plot: 
tm_shape(vole_raster) +
  tm_raster(midpoint = NA, 
            palette = "Blues", 
            legend.show = FALSE)

```
Nearest neighbor (G-function)
```{r}
r <- seq(0,0.15, by = 0.005)

gfunction <- envelope(voles_pb, fun = Gest, r = r, nsim = 100, nrank = 2) # Sig level of Monte Carlo = 0.04

plot(gfunction$obs ~ gfunction$r, type = "l", col = "black", lty = 11)
lines(gfunction$hi ~ gfunction$r, type = "l", col = "blue", lty = 8)
lines(gfunction$theo ~ gfunction$r, type = "l", col = "red", lty = 6)
lines(gfunction$lo ~ gfunction$r, type = "l", col = "green", lty = 4)

# Confirms, in combination with quadrat.test, clustered data!

```
Nearest Neighbor by Ripley's K (using L standardization)

```{r}
r2 <- seq(0,0.5, by = 0.05)

lfunction <- envelope(voles_pb, fun = Lest, r = r2, nsim = 20, rank = 2, global = TRUE)

plot(lfunction$obs ~ lfunction$r, type = "l", col = "black", lty = 11)
lines(lfunction$hi ~ lfunction$r, type = "l", col = "blue", lty = 8)
lines(lfunction$theo ~ lfunction$r, type = "l", col = "red", lty = 6)
lines(lfunction$lo ~ lfunction$r, type = "l", col = "green", lty = 4)

```

Diggle-Cressie-Loosmore-Ford test of CSR
```{r}

DCLFTest <- dclf.test(voles_pb, nsim = 100, rank = 2) 
DCLFTest

```


## Cluster analysis

### k-means

```{r}
iris_nice <- iris %>% 
  clean_names()

# check out the data to see if there are obvious clusters
ggplot(data = iris_nice)+
  geom_point(aes(x = petal_length, 
                 y = petal_width,
                 color = species))

# can ask R: how many clusters do YOU think there should be for this dataset?

number_est <- NbClust(iris_nice[1:4], #only look at first four columns of iris_nice
                      min.nc = 2, # minimum number of clusters to consider should be 2
                      max.nc = 10, # max to consider should be 10
                      method = "kmeans") # we want to use a k-means 

# R is recommending 2 clusters but we know there are three species in the iris dataset so it makes more sense to use 3 clusters


# no we do kmeans:

iris_km <- kmeans(iris_nice[1:4], 3)

# bind the cluster number together with the original data:

iris_cl <- data.frame(iris_nice, cluster_no = factor(iris_km$cluster))

# look at different clusters and how they appear

ggplot(iris_cl)+
  geom_point(aes(x = sepal_length,
                 y = sepal_width,
                 color = cluster_no))

```


```{r}
plot_ly(x = iris_cl$petal_length,
        y = iris_cl$petal_width,
        z = iris_cl$sepal_width, 
        type = "scatter3d",
        color = iris_cl$cluster_no)


```


#### Heirarchical cluster analysis

- 'stats::hclust()' - agglomerative heirarchical clustering
- 'cluster::diana()' - divisive heirarchical clustering

```{r}
wb_env <- read_csv(here("data", "wb_env.csv"))

wb_ghg_20 <- wb_env %>% 
  arrange(-ghg) %>% # arrange in decending order of ghg
  head(20) # also could use top_n from dplyr, use top_frac to specify a fraction of rows to keep

#need to scale numeric variables only so they can be compared, now all on zscale
wb_scaled <- as.data.frame(scale(wb_ghg_20[3:7])) 

rownames(wb_scaled) <- wb_ghg_20$name #make country names row names in scaled dataframe so we know whats what!

# finding distances (a dissimilarity matrix)

diss <- dist(wb_scaled, method = "euclidean", upper = TRUE)

# now use euclidean distances to do some complete agglomerative clustering

hc_complete <- hclust(diss, method = "complete")

# plot it:

plot(hc_complete)



ggdendrogram(hc_complete,
             rotate = TRUE)+
  theme_minimal()+
  labs(x = "Country")

```






